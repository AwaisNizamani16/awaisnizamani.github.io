<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Awais Nizamani</title>

    <meta name="author" content="Awais Nizamani">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Awais Nizamani
                </p>
                
		<p>I am an AI Phd Candidate at <a href="https://www.murdoch.edu.au/">Murdoch University (MU)</a> and <a href="https://www.uwa.edu.au/">The University of Western Australia (UWA)</a> in Perth Australia, where I am working on <a href="https://research-repository.uwa.edu.au/en/projects/intelligent-virtual-human-companions">Intelligent Virtual Humans</a> under the supervision of <a href="https://scholar.google.com/citations?user=Qxmqp-0AAAAJ&hl=en">Prof. Hamid Laga</a>, <a href="https://scholar.google.com/citations?user=ylX5MEAAAAAJ&hl=en">Prof. Mohammed Bennamoun</a>, and <a href="https://scholar.google.com/citations?user=SacY05oAAAAJ&hl=en">Prof. Farid Boussaid</a>, which is funded by the Australia Research Council (ARC). </p> 
		
    <p>Prior to PhD, I worked at <a href="https://retrocausal.ai/">Retrocausal</a> for 3 years as an Applied Research Engineer (Computer Vision) under the supervision of <a href="https://scholar.google.com/citations?user=xE_pSDAAAAAJ&hl=en">Dr. Zeeshan Zia</a> and <a href="https://scholar.google.com/citations?user=8JbK0V8AAAAJ&hl=en">Dr. Quoc-Huy Tran</a>. </p>
		
    </p> In 2020, I completed my undergrad Computer Science from <a href="https://nu.edu.pk/">FAST-NUCES</a> Karachi, Pakistan, where I worked on Multimodal classification datasets under the guidance of <a href="https://scholar.google.com/citations?user=Y_kxezwAAAAJ&hl=en">Prof. Tahir Syed</a>.</p>
                <p style="text-align:center">
                  <a href="mailto:awaisnizamani125@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/awaisnizamani-cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=m7NIJWMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/awais-ahmed-nizamani-808931159/">Linkedin</a> &nbsp;/&nbsp;
                  <a href="https://github.com/AwaisNizamani16/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/AwaisNizamani.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/AwaisNizamani.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  I am interested in computer vision, deep learning, generative AI, and image processing. My research is about video understanding and shape analysis inferring the shape and motion from 3D data or videos. Papers are highlighted in reverse chronological order. '*' denotes equal contribution.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- Publication 1 -->
            <tr onmouseout="dns_stop()" onmouseover="dns_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="dns_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/cvpr25.gif" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/cvpr25.gif" width="160">
                </div>
                <script type="text/javascript">
                  function dns_start() { document.getElementById('dns_image').style.opacity = "1"; }
                  function dns_stop() { document.getElementById('dns_image').style.opacity = "0"; }
                  dns_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Dynamic Neural Surfaces for Elastic 4D Shape Representation and Analysis</span>
                <br>
                <strong>Awais Nizamani*</strong>,
                Hamid Laga,
                Gaunjin Wang,
                Farid Boussaid,
                Mohammed Bennamoun,
                Anuj Srivastava
                <br>
                <em>CVPR</em>, 2025
                <br>
                <a href="https://4d-dsns.github.io/DSNS/">project page</a> /
                <a href="https://arxiv.org/abs/2503.03132">arXiv</a>
                <p></p>
                <p>
                  We introduce Dynamic Neural Surfaces (DNS) for 4D shape representation, enabling elastic and diffeomorphic modeling of complex shape dynamics.
                </p>
              </td>
            </tr>

            <!-- Publication 2 -->
            <tr onmouseout="uas_stop()" onmouseover="uas_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="uas_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/cvpr22.gif" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/cvpr22.gif" width="160">
                </div>
                <script type="text/javascript">
                  function uas_start() { document.getElementById('uas_image').style.opacity = "1"; }
                  function uas_stop() { document.getElementById('uas_image').style.opacity = "0"; }
                  uas_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Unsupervised Action Segmentation by Joint Representation Learning and Online Clustering</span>
                <br>
                Sateesh Kumar*,
                Sanjay Haresh*,
                <strong>Awais Ahmed</strong>,
                Andrey Konin,
                M. Zeeshan Zia,
                Quoc-Huy Tran
                <br>
                <em>CVPR</em>, 2022
                <br>
                <a href="https://retrocausal.ai/research/">project page</a> /
                <a href="https://arxiv.org/abs/2105.13353">arXiv</a>
                <p></p>
                <p>
                  A novel unsupervised approach for action segmentation, combining representation learning with online clustering for temporal consistency.
                </p>
              </td>
            </tr>

            <!-- Publication 3 -->
            <tr onmouseout="tsas_stop()" onmouseover="tsas_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="tsas_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/tsas.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/iros22.png" width="160">
                </div>
                <script type="text/javascript">
                  function tsas_start() { document.getElementById('tsas_image').style.opacity = "1"; }
                  function tsas_stop() { document.getElementById('tsas_image').style.opacity = "0"; }
                  tsas_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Timestamp Supervised Action Segmentation with Graph Convolutional Networks</span>
                <br>
                Hamza Khan*,
                Sanjay Haresh,
                <strong>Awais Ahmed</strong>,
                Shakeeb Siddiqui,
                Andrey Konin,
                M. Zeeshan Zia,
                Quoc-Huy Tran
                <br>
                <em>IROS</em>, 2022
                <br>
                <a href="https://retrocausal.ai/research/">project page</a> /
                <a href="https://arxiv.org/abs/2206.15031">arXiv</a>
                <p></p>
                <p>
                  We propose a GCN-based framework for timestamp-supervised action segmentation, reducing annotation requirements while maintaining accuracy.
                </p>
              </td>
            </tr>

            <!-- Publication 4 -->
            <tr onmouseout="dar_stop()" onmouseover="dar_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="dar_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/dar.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/iccc22.png" width="160">
                </div>
                <script type="text/javascript">
                  function dar_start() { document.getElementById('dar_image').style.opacity = "1"; }
                  function dar_stop() { document.getElementById('dar_image').style.opacity = "0"; }
                  dar_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">Dataset Augmentation Strategies for Visual Activity Recognition in Deep Neural Networks</span>
                <br>
                <strong>Awais Ahmed Nizamani</strong>
                <br>
                <em>ICCC</em>, 2022
                <br>
                <a href="https://ieeexplore.ieee.org/document/10065716">paper</a>
                <p></p>
                <p>
                  A study on augmentation techniques for enhancing generalization in visual activity recognition using deep neural networks.
                </p>
              </td>
            </tr>

            <!-- Publication 5 -->
            <tr onmouseout="ar_stop()" onmouseover="ar_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="ar_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/ar.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/ismar22.png" width="160">
                </div>
                <script type="text/javascript">
                  function ar_start() { document.getElementById('ar_image').style.opacity = "1"; }
                  function ar_stop() { document.getElementById('ar_image').style.opacity = "0"; }
                  ar_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">AI-mediated Job Status Tracking in AR as a No-Code Service</span>
                <br>
                Andrey Konin,
                Shakeeb Siddiqui,
                Hasan Gilani,
                Muhammad Mudassir,
                M. Hassan Ahmed,
                Taban Shaukat,
                Muhammad Naufil,
                <strong>Awais Ahmed</strong>,
                Quoc-Huy Tran,
                M. Zeeshan Zia
                <br>
                <em>ISMAR</em>, 2022
                <br>
                <a href="https://retrocausal.ai/research/">project page</a> /
                <a href="https://ieeexplore.ieee.org/document/9974204">paper</a>
                <p></p>
                <p>
                  We present a no-code AI-mediated AR system for job tracking, enabling intuitive monitoring and reporting in industrial workflows.
                </p>
              </td>
            </tr>

            <!-- Publication 6 -->
            <tr onmouseout="pat_stop()" onmouseover="pat_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="pat_image">
                    <video width=100% height=100% muted autoplay loop>
                      <source src="images/patent.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="images/patent22.png" width="160">
                </div>
                <script type="text/javascript">
                  function pat_start() { document.getElementById('pat_image').style.opacity = "1"; }
                  function pat_stop() { document.getElementById('pat_image').style.opacity = "0"; }
                  pat_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">System and Method for Determining Sub-activities in Videos and Segmenting with Little to No Annotation</span>
                <br>
                Muhammad Shakeeb Hussain Siddiqui,
                Quoc-Huy Tran,
                Muhammad Zeeshan Zia,
                Andrey Konin,
                Sateesh Kumar,
                Sanjay Haresh,
                <strong>Awais Ahmed</strong>,
                Hamza Khan
                <br>
                <em>US Patent</em>, 2022
                <br>
                <a href="https://patents.google.com/patent/US20220383638A1/en">patent link</a>
                <p></p>
                <p>
                  Patent describing a system for fine-grained video activity segmentation with minimal supervision.
                </p>
              </td>
            </tr>


          </tbody></table>
  </body>
</html>
